https://dev.mysql.com/doc/internals/en/transactions-data-layout.html

-------------------------------------------------------------------
operation encapsulation:
/sql/sql_data_change.h This class encapsulates a data change operation. the related .h and .cc file will lead to actual result we need 
- ha_rows: is a number
- this is an in-memory data structure to store informaion on table to operate on and which column is goign to be updated as some default update
  methods (for example auto increment I guess)

-TABEL is defined in/mysql/table.h

-------------------------------------------------------------------
/sql/sql_insert.h

Query_result_insert
-It is likely to be used for both destination to 1 or more tables
     @param table_list_par   The table reference for the destination table.
     @param table_par        The destination table. May be NULL.
-  this code support insert part and onconflict update part so it has multiple COPY_INFO

Query_result_create
- inherits Query_result_insert
- This is used to create table

Sql_cmd_insert extends Sql_cmd_insert_base

Sql_cmd_insert_select
-------------------------------------------------------------------
main implementation (lowel level impl)
/sql/sql_insert.cc

Query_result_insert::xxxx can be used to find mapping between .h and .cc

Plan: start from 
Sql_cmd_insert::
check what is done there


bool Sql_cmd_insert::execute(THD *thd)

- open_temporary_tables() 

TODO: think about why we do things in this way!!!!

Query_result_insertï¼š 
- need_explain_interceptor () always return true
- prepare() Create the new table from the selected items.
  - create_table_from_items() is invoked to create table, it is going to generate a table with fields only for the selected cols/ or just open existing
- prepare2() 
  - If the result table is the same as one of the source tables (INSERT SELECT),
    the result table is not finally prepared at the join prepair phase.
    Do the final preparation now.
- send_data() *****
  - this write the data to disk? and then return the result of write
  - this is calling write_records() which is also part of the class, faile to understand what iss actually done
  - restore_record() is called in some casee due to changed by on conflict update
  - the return value is whether it fails
- store_values() ***
  - It is filling in the values to table????? not actual write I think
  - Item is a parse tree node
  - fill_record_n_invoke_before_triggers() is invoked, restore_record is done as well. This is in /sql/sql_base.cc. it calls fill_record() to fill in fields with the values
    - fail to understand it as well****
 
 - write_record()
  -  Write a record to table with optional deletion of conflicting records, invoke proper triggers if needed.
  - it is going to write staff to table buffer
  - it is trying to write to tables file one by one (to buffer only I think) error=table->file->ha_write_row(table->record[0])
    - int handler::ha_write_row(uchar *buf)
      - mark transtraction as read_write
      - write data to buffer MYSQL_TABLE_IO_WAIT()
        - MYSQL_TABLE_IO_WAIT(PSI_TABLE_WRITE_ROW, MAX_KEY, error, { error= write_row(buf); }), the write_row() is going to be executed based on case
      - write bin log to its table binlog_log_row() 
      - the write_row(buf) is going to STORAGE_ENGINE!!!! , one example is ha_innodb.cc

/storage/innobase/handler/ha_innodb.cc
ha_innobase::write_row()
- it seems it is using some thread context strategy to find the sql query etc
-  insert graph is build and executed: 
   - mysql_row_templ_t*	templ is build as the graph
      - /* A struct describing a place for an individual column in the MySQL
             row format which is presented to the table handler in ha_innobase.
             This template struct is used to speed up row transformations between
             Innobase and MySQL. */
      - /storage/innobase/include/row0mysql.h
   - innobase_srv_conc_enter_innodb(m_prebuilt);
   - error = row_insert_for_mysql((byte*) record, m_prebuilt);
- afterwords: error handling etc

========================================
INNODB
========================================

  
  InnoDB is a multi-versioned storage engine: it keeps information about old versions of changed rows, to support transactional features such as concurrency and rollback. This information is stored in the tablespace in a data structure called a rollback segment
  
  Each row has last_trans insert/update this row, increasing row id and a pointer to the undo log (rollback segment) for (running trans && used for snapshot read on old staff -> this makes it important to commit trans otherwise we will have a lot of garbage)
  
  In the InnoDB multi-versioning scheme, a row is not physically removed from the database immediately when you delete it with an SQL statement. InnoDB only physically removes the corresponding row and its index records when it discards the update undo log record written for the deletion. This removal operation is called a purge, and it is quite fast, usually taking the same order of time as the SQL statement that did the deletion.
  
  the purge for deleted rows could be lagging if you do insert and delete at same speed,  innodb_max_purge_lag could help to limit it
  
  When a secondary index column is updated, old secondary index records are delete-marked, new records are inserted, and delete-marked records are eventually purged. When a secondary index record is delete-marked or the secondary index page is updated by a newer transaction, InnoDB looks up the database record in the clustered index. In the clustered index, the record's DB_TRX_ID is checked, and the correct version of the record is retrieved from the undo log if the record was modified after the reading transaction was initiated.
  
  Secondary index is updated in a way where new data is directly written while old version is markded as delete and being purged once it is not needed for any read (means trans on it are done)
  
  overing index
An index that includes all the columns retrieved by a query. Instead of using the index values as pointers to find the full table rows, the query returns values from the index structure, saving disk I/O. 


=========================================
INNODB MEMORY STRUCTURE
=========================================

current at https://dev.mysql.com/doc/refman/5.7/en/innodb-buffer-pool.html

Buffer pool
It is using LRU strategy to evict cache.

The pages are saved in to lists, 5/8 are new and remaining are old. The two lists are linked.  The old list is used as canaidate for evict.
If the old page is accessed, it will be moved to top of new list (if access required by user). Tail is going to be evicted at some point I think.

- Linear fatch: fatch based on: if you read pages linearly, following pages will be read as well,  innodb_read_ahead_threshold is going to control how many sequential read is the linke
- Random: this doesn't require sequential read, innodb is going to decide what is going to happen if some sequenal pages are in the buffer pool.

Change Buffer
This is the buffer that used to cache changes to secondary indexes when the index's page is not in buffer pool and apply when they get in buffer pool or running purge operation.

- Unlike clustered index(main index I think), the write on secondary index is very likely not consequective on disk, which leads to random disk access and consumes long time.
  Wait for page to be in buffer pool or do such write together with purge could increase the disk write efficiency.
https://dev.mysql.com/doc/refman/5.7/en/innodb-change-buffer.html

Adaptive hash index
- Hash index is used automically by innodb to achieve better performance. It is helpful for small tables which is likely to fit in memory. In this way the search for item with key is fast.
- There is latch on hashindex so it might be a bottle neck if you have heavy load for  multiple concurrent joins (???) and like or % maching (this makes sense) 
- you can turn it off if needed
- after 56, we have parittion and multiple latch on each parititon for the whole hash index instead of one
https://dev.mysql.com/doc/refman/5.7/en/innodb-adaptive-hash.html


Log buffer -> for redo log
- Buffer to store logs in memory, default to 16MB. It can avoids writing redo log to disk before commit if query is not too big and not fill the buffer. The buffer will periodically
  flush to disk on necessary. Increase the size if you have large write
https://dev.mysql.com/doc/refman/5.7/en/innodb-redo-log-buffer.html


===================================
INNODB DISK STRUCTURE
===================================

- How Secondary Indexes Relate to the Clustered Index
All indexes other than the clustered index are known as secondary indexes. In InnoDB, each record in a secondary index contains the primary key columns for the row, as well as the columns specified for the secondary index. InnoDB uses this primary key value to search for the row in the clustered index.
If the primary key is long, the secondary indexes use more space, so it is advantageous to have a short primary key.

https://dev.mysql.com/doc/refman/5.7/en/innodb-physical-structure.html
