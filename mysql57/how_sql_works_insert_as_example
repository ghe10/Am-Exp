https://dev.mysql.com/doc/internals/en/transactions-data-layout.html

-------------------------------------------------------------------
operation encapsulation:
/sql/sql_data_change.h This class encapsulates a data change operation. the related .h and .cc file will lead to actual result we need 
- ha_rows: is a number
- this is an in-memory data structure to store informaion on table to operate on and which column is goign to be updated as some default update
  methods (for example auto increment I guess)

-TABEL is defined in/mysql/table.h

-------------------------------------------------------------------
/sql/sql_insert.h

Query_result_insert
-It is likely to be used for both destination to 1 or more tables
     @param table_list_par   The table reference for the destination table.
     @param table_par        The destination table. May be NULL.
-  this code support insert part and onconflict update part so it has multiple COPY_INFO

Query_result_create
- inherits Query_result_insert
- This is used to create table

Sql_cmd_insert extends Sql_cmd_insert_base

Sql_cmd_insert_select
-------------------------------------------------------------------
main implementation (lowel level impl)
/sql/sql_insert.cc

Query_result_insert::xxxx can be used to find mapping between .h and .cc

Plan: start from 
Sql_cmd_insert::
check what is done there


bool Sql_cmd_insert::execute(THD *thd)

- open_temporary_tables() 

TODO: think about why we do things in this way!!!!

Query_result_insert： 
- need_explain_interceptor () always return true
- prepare() Create the new table from the selected items.
  - create_table_from_items() is invoked to create table, it is going to generate a table with fields only for the selected cols/ or just open existing
- prepare2() 
  - If the result table is the same as one of the source tables (INSERT SELECT),
    the result table is not finally prepared at the join prepair phase.
    Do the final preparation now.
- send_data() *****
  - this write the data to disk? and then return the result of write
  - this is calling write_records() which is also part of the class, faile to understand what iss actually done
  - restore_record() is called in some casee due to changed by on conflict update
  - the return value is whether it fails
- store_values() ***
  - It is filling in the values to table????? not actual write I think
  - Item is a parse tree node
  - fill_record_n_invoke_before_triggers() is invoked, restore_record is done as well. This is in /sql/sql_base.cc. it calls fill_record() to fill in fields with the values
    - fail to understand it as well****
 
 - write_record()
  -  Write a record to table with optional deletion of conflicting records, invoke proper triggers if needed.
  - it is going to write staff to table buffer
  - it is trying to write to tables file one by one (to buffer only I think) error=table->file->ha_write_row(table->record[0])
    - int handler::ha_write_row(uchar *buf)
      - mark transtraction as read_write
      - write data to buffer MYSQL_TABLE_IO_WAIT()
        - MYSQL_TABLE_IO_WAIT(PSI_TABLE_WRITE_ROW, MAX_KEY, error, { error= write_row(buf); }), the write_row() is going to be executed based on case
      - write bin log to its table binlog_log_row() 
      - the write_row(buf) is going to STORAGE_ENGINE!!!! , one example is ha_innodb.cc

/storage/innobase/handler/ha_innodb.cc
ha_innobase::write_row()
- it seems it is using some thread context strategy to find the sql query etc
-  insert graph is build and executed: 
   - mysql_row_templ_t*	templ is build as the graph
      - /* A struct describing a place for an individual column in the MySQL
             row format which is presented to the table handler in ha_innobase.
             This template struct is used to speed up row transformations between
             Innobase and MySQL. */
      - /storage/innobase/include/row0mysql.h
   - innobase_srv_conc_enter_innodb(m_prebuilt);
   - error = row_insert_for_mysql((byte*) record, m_prebuilt);
- afterwords: error handling etc

========================================
INNODB
========================================

  
  InnoDB is a multi-versioned storage engine: it keeps information about old versions of changed rows, to support transactional features such as concurrency and rollback. This information is stored in the tablespace in a data structure called a rollback segment
  
  Each row has last_trans insert/update this row, increasing row id and a pointer to the undo log (rollback segment) for (running trans && used for snapshot read on old staff -> this makes it important to commit trans otherwise we will have a lot of garbage)
  
  In the InnoDB multi-versioning scheme, a row is not physically removed from the database immediately when you delete it with an SQL statement. InnoDB only physically removes the corresponding row and its index records when it discards the update undo log record written for the deletion. This removal operation is called a purge, and it is quite fast, usually taking the same order of time as the SQL statement that did the deletion.
  
  the purge for deleted rows could be lagging if you do insert and delete at same speed,  innodb_max_purge_lag could help to limit it
  
  When a secondary index column is updated, old secondary index records are delete-marked, new records are inserted, and delete-marked records are eventually purged. When a secondary index record is delete-marked or the secondary index page is updated by a newer transaction, InnoDB looks up the database record in the clustered index. In the clustered index, the record's DB_TRX_ID is checked, and the correct version of the record is retrieved from the undo log if the record was modified after the reading transaction was initiated.
  
  Secondary index is updated in a way where new data is directly written while old version is markded as delete and being purged once it is not needed for any read (means trans on it are done)
  
  overing index
An index that includes all the columns retrieved by a query. Instead of using the index values as pointers to find the full table rows, the query returns values from the index structure, saving disk I/O. 


=========================================
INNODB MEMORY STRUCTURE
=========================================

current at https://dev.mysql.com/doc/refman/5.7/en/innodb-buffer-pool.html

Buffer pool
It is using LRU strategy to evict cache.

The pages are saved in to lists, 5/8 are new and remaining are old. The two lists are linked.  The old list is used as canaidate for evict.
If the old page is accessed, it will be moved to top of new list (if access required by user). Tail is going to be evicted at some point I think.

- Linear fatch: fatch based on: if you read pages linearly, following pages will be read as well,  innodb_read_ahead_threshold is going to control how many sequential read is the linke
- Random: this doesn't require sequential read, innodb is going to decide what is going to happen if some sequenal pages are in the buffer pool.

Change Buffer
This is the buffer that used to cache changes to secondary indexes when the index's page is not in buffer pool and apply when they get in buffer pool or running purge operation.

- Unlike clustered index(main index I think), the write on secondary index is very likely not consequective on disk, which leads to random disk access and consumes long time.
  Wait for page to be in buffer pool or do such write together with purge could increase the disk write efficiency.
https://dev.mysql.com/doc/refman/5.7/en/innodb-change-buffer.html

Adaptive hash index
- Hash index is used automically by innodb to achieve better performance. It is helpful for small tables which is likely to fit in memory. In this way the search for item with key is fast.
- There is latch on hashindex so it might be a bottle neck if you have heavy load for  multiple concurrent joins (???) and like or % maching (this makes sense) 
- you can turn it off if needed
- after 56, we have parittion and multiple latch on each parititon for the whole hash index instead of one
https://dev.mysql.com/doc/refman/5.7/en/innodb-adaptive-hash.html


Log buffer -> for redo log
- Buffer to store logs in memory, default to 16MB. It can avoids writing redo log to disk before commit if query is not too big and not fill the buffer. The buffer will periodically
  flush to disk on necessary. Increase the size if you have large write
https://dev.mysql.com/doc/refman/5.7/en/innodb-redo-log-buffer.html


===================================
INNODB DISK STRUCTURE
===================================

- How Secondary Indexes Relate to the Clustered Index
All indexes other than the clustered index are known as secondary indexes. In InnoDB, each record in a secondary index contains the primary key columns for the row, as well as the columns specified for the secondary index. InnoDB uses this primary key value to search for the row in the clustered index.
If the primary key is long, the secondary indexes use more space, so it is advantageous to have a short primary key.

https://dev.mysql.com/doc/refman/5.7/en/innodb-physical-structure.html

--------------------------
Innodb index
spatial index uses R tree, in all other cases, innodb is using btree
Innodb is going to reserve some space in each page (default max is 15/16) for future use (trying to, not guarantee)
If it is below 50% usage, it will do a merge

page size: Supported sizes are 64KB, 32KB, 16KB (default), 8KB, and 4KB. If you define the page size, it can't be changed, and other instance with different page size won't be able to do anything on it for backup etc

- Sorted Index build
This is using a bottom up way of generating the index.
- step one, do a scan with sort buffer, when buffer full, sort write to tmp file
- step two, when all scan done, do a merge sort from files.
- step three, insert into btree
  - bottom up approach: point to right most page of all levels of the tree currently have, insert until we get page full (reaching usage factor), then we move the point to next right page that is allocated, insert.
  - parent link are added when leaf page is full (I assume same for other levels)
  
we still uses innodb_fill_factor to configure the usage of a page when we build it.
Note: the TEXT and BLOB pages which are linked out of the regular leaf pages are not controlled by the usage factor.

https://dev.mysql.com/doc/refman/5.7/en/sorted-index-builds.html

---------------------------
InnoDB Full-Text Index Design
InnoDB FULLTEXT indexes have an inverted index design. Inverted indexes store a list of words, and for each word, a list of documents that the word appears in. To support proximity search, position information for each word is also stored, as a byte offset.

The reverse index is done in a way that is placed in multiple INDEX tables in a partioned fashion. When deletion happens, instead of update all the partitions etc, it is going to add the deletion info in a separate full text deletion table.
When full text related query is executed, it is going to do separate filter and check the delete table to remove results that shouldn't be returned.

The index is store in a way where words is mapping to what document it appears in.

Full text index has an insert buffer to avoid a lot of small writes happens and slow down the DB
https://dev.mysql.com/doc/refman/5.7/en/innodb-fulltext-index.html

---------------------------
Table spaces

The system tablespace is the storage area for the InnoDB data dictionary, the doublewrite buffer, the change buffer, and undo logs. It may also contain table and index data if tables are created in the system tablespace rather than file-per-table or general tablespaces.

The system tablespace can have one or more data files. By default, a single system tablespace data file, named ibdata1, is created in the data directory. The size and number of system tablespace data files is defined by the innodb_data_file_path startup option. For configuration information, see System Tablespace Data File Configuration.

A file-per-table tablespace contains data and indexes for a single InnoDB table, and is stored on the file system in its own data file.

A general tablespace is a shared InnoDB tablespace that is created using CREATE TABLESPACE syntax
- it has slight memory advantage over file per table space as its metadata is kept in memory all the time unlinke the file per table
- it supports everything

Undo tablespaces contain undo logs, which are collections of undo log records that contain information about how to undo the latest change by a transaction to a clustered index record. Undo logs exist within undo log segments, which are contained within rollback segments. The innodb_rollback_segments variable defines the number of rollback segments allocated to each undo tablespace.
Undo logs can be stored in one or more undo tablespaces instead of the system tablespace. This layout differs from the default configuration in which undo logs reside in the system tablespace. The I/O patterns for undo logs make undo tablespaces good candidates for SSD storage, while keeping the system tablespace on hard disk storage.
The number of undo tablespaces used by InnoDB is controlled by the innodb_undo_tablespaces configuration option. This option can only be configured when initializing the MySQL instance. It cannot be changed afterward.
https://dev.mysql.com/doc/refman/5.7/en/innodb-undo-tablespaces.html

temporary tablespace.
Non-compressed, user-created temporary tables and on-disk internal temporary tables are created in a shared temporary tablespace. The innodb_temp_data_file_path configuration option defines the relative path, name, size, and attributes for temporary tablespace data files. If no value is specified for innodb_temp_data_file_path, the default behavior is to create an auto-extending data file named ibtmp1 in the innodb_data_home_dir directory that is slightly larger than 12MB.

This is removed up on restart and recreated. Recreation failure will cause restart failure

------------------------------------
InnoDB Data Dictionary
The InnoDB data dictionary is comprised of internal system tables that contain metadata used to keep track of objects such as tables, indexes, and table columns. The metadata is physically located in the InnoDB system tablespace. For historical reasons, data dictionary metadata overlaps to some degree with information stored in InnoDB table metadata files (.frm files).

-----------------------------------
https://dev.mysql.com/doc/refman/5.7/en/innodb-doublewrite-buffer.html

-----------------------------------
double write buffer

The doublewrite buffer is a storage area where InnoDB writes pages flushed from the buffer pool before writing the pages to their proper positions in the InnoDB data files. If there is an operating system, storage subsystem, or mysqld process crash in the middle of a page write, InnoDB can find a good copy of the page from the doublewrite buffer during crash recovery.

This can provide better recovery strategy, as it only needs a big block write instead of multiple random disk staff


-----------------------------------
Redo log

The redo log is a disk-based data structure used during crash recovery to correct data written by incomplete transactions. During normal operations, the redo log encodes requests to change table data that result from SQL statements or low-level API calls. Modifications that did not finish updating the data files before an unexpected shutdown are replayed automatically during initialization, and before the connections are accepted. For information about the role of the redo log in crash recovery, see Section 14.19.2, “InnoDB Recovery”.

By default, the redo log is physically represented on disk by two files named ib_logfile0 and ib_logfile1. MySQL writes to the redo log files in a circular fashion. Data in the redo log is encoded in terms of records affected; this data is collectively referred to as redo. The passage of data through the redo log is represented by an ever-increasing LSN value.

It helps when the flush data to disk is not done and crash happen in the middle.

-----------------------------------
Undo log

This is used ass crash recovery as well. It is going to be applied to undo log segment and will be used to recover the change if we see some transtractions
that reserve read image for old data. Besides, in recovery it can be used to rollback not committed transtractions.

Innodb has 128 rollback segments and 32 of them are reserved for tmp table name space. Each page can have 16 undo slots, each can map to a transtraction's usage.

Note that one transtraction could need multiple such slot as it can have different operations.

Undo logs are assigned as needed. For example, a transaction that performs INSERT, UPDATE, and DELETE operations on regular and temporary tables requires a full assignment of four undo logs. A transaction that performs only INSERT operations on regular tables requires a single undo log.

A transaction that performs operations on regular tables is assigned undo logs from an assigned system tablespace or undo tablespace rollback segment. A transaction that performs operations on temporary tables is assigned undo logs from an assigned temporary tablespace rollback segment.

If your transtractions use up the undo space, it is going to be stuck somehow. ?????? how to recover? suggested was rerun transtraction
https://dev.mysql.com/doc/refman/5.7/en/innodb-undo-logs.html

=================================================



